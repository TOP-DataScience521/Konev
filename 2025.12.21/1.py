import numpy as np
from neuron2 import Neuron, DenseLayer
from activations import step, linear, relu, lrelu, prelu, sigmoid, tanh

#=======Проверка выхода сигмойды
input_data = np.array([4.0, -1.0, -0.5, 0.5, 1.0,2.0 ])
total_sum = input_data.sum()

layer = DenseLayer(
    n=2,                    
    activation_func=sigmoid,   
)
output = layer.out(input_data) 
print("=" * 50)
print(f" Проверка 1 сигмойды № 1 ")
print(f" входной массив данных: {input_data} ")
print(f" сумматор: {total_sum} ")
print(f" выходное значение активационной функции {output}")

input_data = np.array([-8.0, -1.0, -0.5, 0.5, 1.0,2.0 ])
total_sum = input_data.sum()

layer = DenseLayer(
    n=2,                    
    activation_func=sigmoid,    
)
output = layer.out(input_data) 
print("-" * 50)
print(f" Проверка 2 сигмойды № 2 ")
print(f" входной массив данных: {input_data} ")
print(f" сумматор: {total_sum} ")
print(f" выходное значение активационной функции {output}")
print("=" * 50)

#=======Проверка выхода релу
input_data = np.array([4.0, -1.0, -0.5, 0.5, 1.0,2.0 ])
total_sum = input_data.sum()

layer = DenseLayer(
    n=2,                    
    activation_func=relu,   
)
output = layer.out(input_data) 
print("=" * 50)
print(f" Проверка 3 relu № 1 ")
print(f" входной массив данных: {input_data} ")
print(f" сумматор: {total_sum} ")
print(f" выходное значение активационной функции {output}")



input_data = np.array([-8.0, -1.0, -0.5, 0.5, 1.0,2.0 ])
total_sum = input_data.sum()

layer = DenseLayer(
    n=2,                    
    activation_func=relu,    
)
output = layer.out(input_data) 
print("-" * 50)
print(f" Проверка 4 relu № 2 ")
print(f" входной массив данных: {input_data} ")
print(f" сумматор: {total_sum} ")
print(f" выходное значение активационной функции {output}")
print("=" * 50)



#=======Проверка выхода tanh
input_data = np.array([4.0, -1.0, -0.5, 0.5, 1.0,2.0 ])
total_sum = input_data.sum()

layer = DenseLayer(
    n=2,                    
    activation_func=tanh,   
)
output = layer.out(input_data) 
print("=" * 50)
print(f" Проверка 5 tanh № 1 ")
print(f" входной массив данных: {input_data} ")
print(f" сумматор: {total_sum} ")
print(f" выходное значение активационной функции {output}")



input_data = np.array([-8.0, -1.0, -0.5, 0.5, 1.0,2.0 ])
total_sum = input_data.sum()

layer = DenseLayer(
    n=2,                    
    activation_func=tanh,    
)
output = layer.out(input_data) 
print("-" * 50)
print(f" Проверка 6 tanh № 2 ")
print(f" входной массив данных: {input_data} ")
print(f" сумматор: {total_sum} ")
print(f" выходное значение активационной функции {output}")
print("=" * 50)


#=======Работа с тремя слоями с разными функциями


input_data = np.array([4.0, -1.0, -0.5, 0.5, 1.0, 2.0])
total_sum = input_data.sum()

print("=" * 50)
print(f" Проверка 7: работа с тремя слоями №1")
print(f" Входной массив данных: {input_data}")
print(f" Сумматор: {total_sum}")

# Первый слой: 2 нейрона с tanh
layer = DenseLayer(
    n=2,                    
    activation_func=tanh,   
)
output1 = layer.out(input_data) 
print(f"\nВыход первого слоя (2 нейрона, tanh): {output1}")

# Второй слой: 4 нейрона с sigmoid (вход = выход первого слоя)
layer2 = DenseLayer(
    n=4,                    # 4 нейрона в слое
    activation_func=sigmoid,   # функция активации sigmoid
)
output2 = layer2.out(output1)  # передаем выход первого слоя
print(f"Выход второго слоя (4 нейрона, sigmoid): {output2}")

# Третий слой: 6 нейронов с relu (вход = выход второго слоя)
layer3 = DenseLayer(
    n=6,                    # 6 нейронов в слое
    activation_func=relu,   # функция активации sigmoid
)
output3 = layer3.out(output2)  # передаем выход второго слоя
print(f"Выход третьего слоя (6 нейронов, relu): {output3}")

print("=" * 50)
print("Итоговый выход сети:", output3)








input_data = np.array([-8.0, -1.0, -0.5, 0.5, 1.0,2.0 ])
total_sum = input_data.sum()

print("=" * 50)
print(f" Проверка 8: работа с тремя слоями №2")
print(f" Входной массив данных: {input_data}")
print(f" Сумматор: {total_sum}")

# Первый слой: 2 нейрона с tanh
layer = DenseLayer(
    n=2,                    
    activation_func=tanh,   
)
output1 = layer.out(input_data) 
print(f"\nВыход первого слоя (2 нейрона, tanh): {output1}")

# Второй слой: 4 нейрона с sigmoid (вход = выход первого слоя)
layer2 = DenseLayer(
    n=4,                    # 4 нейрона в слое
    activation_func=sigmoid,   # функция активации sigmoid
)
output2 = layer2.out(output1)  # передаем выход первого слоя
print(f"Выход второго слоя (4 нейрона, sigmoid): {output2}")

# Третий слой: 6 нейронов с relu (вход = выход второго слоя)
layer3 = DenseLayer(
    n=6,                    # 6 нейронов в слое
    activation_func=relu,   # функция активации sigmoid
)
output3 = layer3.out(output2)  # передаем выход второго слоя
print(f"Выход третьего слоя (6 нейронов, relu): {output3}")

print("=" * 50)
print("Итоговый выход сети:", output3)








#==================================================
# Проверка 1 сигмойды № 1
# входной массив данных: [ 4.  -1.  -0.5  0.5  1.   2. ]
# сумматор: 6.0
# выходное значение активационной функции [0.99752738 0.99752738]
#--------------------------------------------------
# Проверка 2 сигмойды № 2
# входной массив данных: [-8.  -1.  -0.5  0.5  1.   2. ]
# сумматор: -6.0
# выходное значение активационной функции [0.00247262 0.00247262]
#==================================================
#==================================================
# Проверка 3 relu № 1
# входной массив данных: [ 4.  -1.  -0.5  0.5  1.   2. ]
# сумматор: 6.0
# выходное значение активационной функции [6. 6.]
#--------------------------------------------------
# Проверка 4 relu № 2
# входной массив данных: [-8.  -1.  -0.5  0.5  1.   2. ]
# сумматор: -6.0
# выходное значение активационной функции [0. 0.]
#==================================================
#==================================================
# Проверка 5 tanh № 1
# входной массив данных: [ 4.  -1.  -0.5  0.5  1.   2. ]
# сумматор: 6.0
# выходное значение активационной функции [0.99998771 0.99998771]
#--------------------------------------------------
# Проверка 6 tanh № 2
# входной массив данных: [-8.  -1.  -0.5  0.5  1.   2. ]
# сумматор: -6.0
# выходное значение активационной функции [-0.99998771 -0.99998771]
#==================================================
#==================================================
# Проверка 7: работа с тремя слоями №1
# Входной массив данных: [ 4.  -1.  -0.5  0.5  1.   2. ]
# Сумматор: 6.0
#
#Выход первого слоя (2 нейрона, tanh): [0.99998771 0.99998771]
#Выход второго слоя (4 нейрона, sigmoid): [0.8807945 0.8807945 0.8807945 0.8807945]
#Выход третьего слоя (6 нейронов, relu): [3.52317799 3.52317799 3.52317799 3.52317799 3.52317799 3.52317799]
#==================================================
#Итоговый выход сети: [3.52317799 3.52317799 3.52317799 3.52317799 3.52317799 3.52317799]
#==================================================
# Проверка 8: работа с тремя слоями №2
# Входной массив данных: [-8.  -1.  -0.5  0.5  1.   2. ]
# Сумматор: -6.0
#
#Выход первого слоя (2 нейрона, tanh): [-0.99998771 -0.99998771]
#Выход второго слоя (4 нейрона, sigmoid): [0.1192055 0.1192055 0.1192055 0.1192055]
#Выход третьего слоя (6 нейронов, relu): [0.47682201 0.47682201 0.47682201 0.47682201 0.47682201 0.47682201]
#==================================================
#Итоговый выход сети: [0.47682201 0.47682201 0.47682201 0.47682201 0.47682201 0.47682201]