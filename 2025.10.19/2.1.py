#          CRIM     ZN  INDUS   CHAS    NOX     RM    AGE    DIS    RAD    TAX  PTRATIO      B  LSTAT   MEDV
#CRIM     1.000 -0.386  0.571 -0.007  0.621 -0.264  0.528 -0.562  0.677  0.656    0.378 -0.373  0.545 -0.474
#ZN      -0.386  1.000 -0.588 -0.042 -0.576  0.337 -0.557  0.640 -0.295 -0.343   -0.420  0.169 -0.452  0.399
#INDUS    0.571 -0.588  1.000  0.076  0.777 -0.403  0.662 -0.733  0.525  0.693    0.408 -0.321  0.621 -0.531
#CHAS    -0.007 -0.042  0.076  1.000  0.080  0.075  0.077 -0.090  0.009 -0.040   -0.129  0.004 -0.052  0.158
#NOX      0.621 -0.576  0.777  0.080  1.000 -0.306  0.763 -0.825  0.599  0.659    0.290 -0.338  0.614 -0.495
#RM      -0.264  0.337 -0.403  0.075 -0.306  1.000 -0.259  0.234 -0.159 -0.282   -0.334  0.091 -0.627  0.664
#AGE      0.528 -0.557  0.662  0.077  0.763 -0.259  1.000 -0.775  0.437  0.516    0.308 -0.251  0.630 -0.462
#DIS     -0.562  0.640 -0.733 -0.090 -0.825  0.234 -0.775  1.000 -0.495 -0.554   -0.277  0.271 -0.531  0.348
#RAD      0.677 -0.295  0.525  0.009  0.599 -0.159  0.437 -0.495  1.000  0.808    0.392 -0.363  0.441 -0.364
#TAX      0.656 -0.343  0.693 -0.040  0.659 -0.282  0.516 -0.554  0.808  1.000    0.457 -0.386  0.539 -0.515
#PTRATIO  0.378 -0.420  0.408 -0.129  0.290 -0.334  0.308 -0.277  0.392  0.457    1.000 -0.125  0.421 -0.532
#B       -0.373  0.169 -0.321  0.004 -0.338  0.091 -0.251  0.271 -0.363 -0.386   -0.125  1.000 -0.288  0.260
#LSTAT    0.545 -0.452  0.621 -0.052  0.614 -0.627  0.630 -0.531  0.441  0.539    0.421 -0.288  1.000 -0.795
#MEDV    -0.474  0.399 -0.531  0.158 -0.495  0.664 -0.462  0.348 -0.364 -0.515   -0.532  0.260 -0.795  1.000

# Выше представлена матрица являющаяся средней арифмитической между матричей Спирмена и Пирсона
# относительно MEDV были выбраны все переменные выше 0,4 по модулу
# у каждой перменной будет число корреляций с другими переменными выше 0,4 по модулу
# это переменные CRIM 7,INDUS 10,NOX 7,RM 2,AGE 8,TAX 8,PTRATIO 4,LSTAT 10
# пожалуй избавлюсь от переменных с мксимальным значением корреляций с другими переменными тоесть от INDUS 10,LSTAT 10
# и остаются следующие переменные CRIM ,NOX ,RM ,AGE ,TAX ,PTRATIO
# Вариант 2.1   test_rate = 0.10














from pandas import read_csv
from sklearn.linear_model import LinearRegression

from pathlib import Path
from sys import path


script_dir = Path(path[0])

data = read_csv(script_dir / 'boston.csv', comment='#')

# >>> data.shape
# (506, 14)

# отобранные зависимые переменные
effect_vars = ['CRIM', 'NOX', 'RM', 'AGE', 'TAX','PTRATIO']
# целевая переменная
target_var = ['MEDV']

# маска для фильтрации значений
mask = data['MEDV'] != 50

x = data.loc[mask, effect_vars]
y = data.loc[mask, target_var]

# >>> x.shape
# (490, 6)
# >>> y.shape
# (490, 1)


# формирование обучающей и тестовой подвыборок
test_rate = 0.10
i = int(x.shape[0]*(1-test_rate))

x_train, x_test = x.iloc[:i, :], x.iloc[i:, :]
y_train, y_test = y.iloc[:i, :], y.iloc[i:, :]

# >>> x_train.shape, y_train.shape
# ((441, 6), (441, 1))
# >>>
# >>> x_test.shape, y_test.shape
# ((49, 6), (49, 1))


# уравнение функции нескольких переменных для множественной линейной регрессии
# y(x1, x2, x3, x4, x5, x6, x7, x8, x9) = a1*x1 + a2*x2 + a3*x3 + a4*x4 + a5*x5 + a6*x6 + a7*x7 + a8*x8 + a9*x9 + b

# a1, a2, a3, a4, a5, a6, a7, a8, a9, b — это коэффициенты, которые необходимо подобрать, что и происходит во время обучения модели

model = LinearRegression()

# обучение модели
model.fit(x_train, y_train)

# значения коэффициентов-множителей (в примере выше: a1, a2, ..., a9)
# >>> model.coef_
# array([[-0.07925792, -5.18828981,  5.96064228, -0.02699349, -0.01041273,
#        -0.84581909]])

# значение коэффициента-слагаемого (в примере выше: b)
# >>> model.intercept_
# array([9.10609909])


# тестирование модели
y_pred = model.predict(x_test)

# >>> y_pred.shape
# (49, 1)

# метрики:
# среднеквадратичная ошибка
rmse = (((y_test - y_pred)**2).sum() / len(y_test))**0.5
# коэффициент детерминации
r2 = 1 - ((y_test - y_pred)**2).sum() / (((y_test - y_test.mean())**2).sum())
# скорректированный коэффициент детерминации
r2_adj = 1 - (1 - r2)*(x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1)

print(f'RMSE = {rmse.iloc[0]:.1f}\nR2 = {r2.iloc[0]:.0%}\nR2 (adjusted) = {r2_adj.iloc[0]:.0%}')


# RMSE = 3.9
# R2 = 18%
# R2 (adjusted) = 6%

