# импорт логической регресии
from sklearn.linear_model import LogisticRegression

# импорт для разделения обучающей и тестовой выборки
from sklearn.model_selection import train_test_split

# импорт класса датафрейм для табличных данных
from pandas import DataFrame

# импорт новой функции для метрики 
from sklearn.metrics import accuracy_score

# импортирую данные из breast_cancer_init, зависимых и независимых
from breast_cancer_init import data, target

# попробовал упаковать код из breast_cancer_init.py в функцию, для быстрого назначения признаков
def top_dependent_variables(top_n):
    # top_n - количество наиболее значиных признаков в порядке убывания
    
    # нормализуем данные
    data_norm = (data - data.describe().loc['mean', :]) / data.describe().loc['std', :]

    # вычисляем среднии значения для нормализованных признаков соответсвующих целевому значению 0 
    mean_0 = data_norm[target == 0].mean()
    # вычисляем среднии значения для нормализованных признаков соответсвующих целевому значению 1    
    mean_1 = data_norm[target == 1].mean()

    # создаем датафрейм где будет разница между средними значениями нормализованных признаков по убыванию
    groupped_means_diffs = DataFrame({
        'mean_0': mean_0,
        'mean_1': mean_1,
        'diff': abs(mean_0 - mean_1)
    }).sort_values(by='diff', ascending=False)

    # для выбора наиболее значимых признаков с преобразованием в список
    dependent_variables = groupped_means_diffs.head(top_n).index.tolist()
 
    # возращаем список отобранных признаков 
    return list(dependent_variables)



# решил и скрипт для обучения тоже запаковать в функцию
# data - импортируем,
# target - тоже импорт,
# effect_vars - тут будет вызов функции которая соберает значимые признаки
# test_size - обьем тестовой выборки, подумаю позже как ее буду задавать

def train_and_evaluate_model(data, target, effect_vars, test_size):


# train_test_split функция из склен для разделения данных на тестовые и тренировочные
    x_train, x_test, y_train, y_test = train_test_split(
    # из таблицы выбераем все строки с помощью ":" и конкретный столбец со списком effect_vars
        data.loc[:, list(effect_vars)],
        target,
        test_size=test_size,
    # получается тут я запечатываю случайность
        random_state=1
    )
# проводим нормализацию данных 
    x_train_norm = (x_train - x_train.describe().loc['mean', :]) / x_train.describe().loc['std', :]
    x_test_norm = (x_test - x_test.describe().loc['mean', :]) / x_test.describe().loc['std', :]

    model = LogisticRegression()
    
# запускаем процес обучения где   x_train_norm независимые  а  y_train - целевые данные   
    model.fit(x_train_norm, y_train)
    
#  тут запсукаем процес сравнение обученной модели с тестовыми данными   
    y_pred = model.predict(x_test_norm)

    # простая метрика которая судя по всему вычисляет сколько успешных предсказаний и делит на общее количество и выражается в долях
    accuracy = accuracy_score(y_test, y_pred)
 # функция возвращает метрику точности   
    return accuracy

# наверное создам списки , внешне похожие на таблицу
results_table = []

# тут уже вручную буду задавать интерисующие меня обьемы выборок
test_sizes = [0.1, 0.2, 0.3]

print("таблица с результатми")
print("\n" + "-"*80)

# познакомился с отступами типа :<30
print(f"{'признаки':<30} {'test_size=0.1':<15} {'test_size=0.2':<15} {'test_size=0.3':<15}")
print("-"*80)

# цикл для перебора значимых признаков
for num_features in range(1, 31):
    # формирую список самых ажных признаков
    effect_vars = top_dependent_variables(num_features)
    
    # столбец с обозначением количества признаков
    features_display = f"первые {num_features} признаков"
    
    # список в который попробу положить точности по всем обучениям
    accuracies = []
    
    # считаю метрики для каждого бьема тестовой выборки
    for test_size in test_sizes:
        accuracy = train_and_evaluate_model(data, target, effect_vars, test_size)
        accuracies.append(f"{accuracy:.4f}")
    
    # прибавляю строку к импровизированной таблице
    results_table.append({
        'features': features_display,
        'test_0.1': accuracies[0],
        'test_0.2': accuracies[1], 
        'test_0.3': accuracies[2]
    })
    
    # буду выводить по одной строке которая получилась в ходе цикла
    print(f"{features_display:<30} {accuracies[0]:<15} {accuracies[1]:<15} {accuracies[2]:<15}")



# таблица с результатми

# --------------------------------------------------------------------------------
# признаки                       test_size=0.1   test_size=0.2   test_size=0.3
# --------------------------------------------------------------------------------
# первые 1 признаков             0.8947          0.8947          0.8830
# первые 2 признаков             0.9649          0.9386          0.9181
# первые 3 признаков             0.9649          0.9386          0.9181
# первые 4 признаков             0.9649          0.9386          0.9298
# первые 5 признаков             0.9649          0.9386          0.9298
# первые 6 признаков             0.9649          0.9386          0.9298
# первые 7 признаков             0.9649          0.9386          0.9298
# первые 8 признаков             0.9649          0.9386          0.9298
# первые 9 признаков             0.9649          0.9386          0.9240
# первые 10 признаков            0.9649          0.9386          0.9123
# первые 11 признаков            0.9649          0.9386          0.9240
# первые 12 признаков            0.9649          0.9386          0.9298
# первые 13 признаков            0.9649          0.9386          0.9064
# первые 14 признаков            0.9649          0.9386          0.9064
# первые 15 признаков            0.9649          0.9386          0.9064
# первые 16 признаков            0.9825          0.9561          0.9474
# первые 17 признаков            1.0000          0.9649          0.9591
# первые 18 признаков            1.0000          0.9737          0.9649
# первые 19 признаков            1.0000          0.9737          0.9649
# первые 20 признаков            1.0000          0.9737          0.9649
# первые 21 признаков            1.0000          0.9737          0.9649
# первые 22 признаков            1.0000          0.9737          0.9649
# первые 23 признаков            1.0000          0.9737          0.9649
# первые 24 признаков            1.0000          0.9737          0.9591
# первые 25 признаков            1.0000          0.9737          0.9591
# первые 26 признаков            1.0000          0.9737          0.9532
# первые 27 признаков            1.0000          0.9737          0.9532
# первые 28 признаков            1.0000          0.9737          0.9532
# первые 29 признаков            1.0000          0.9737          0.9532
# первые 30 признаков            1.0000          0.9737          0.9532


# результаты немного странные, но получается, лучшие варинты 
# это взять первые 17 значимых признаков и больше, с мнимальной тестовой выборкой, 
# хотелось бы посмотреть на результаты при совокупности от пары тысяч данных там должно быть гораздо интереснее